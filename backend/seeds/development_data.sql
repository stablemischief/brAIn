-- brAIn v2.0 Development Seed Data
-- Purpose: Provide sample data for development and testing
-- Created: 2025-09-11

-- ========================================
-- DEVELOPMENT USERS
-- ========================================

-- Insert development users (using deterministic UUIDs for consistency)
INSERT INTO users (id, email, display_name, role, preferences, settings, monthly_budget_limit) VALUES
    ('11111111-1111-1111-1111-111111111111', 'dev@brain.ai', 'Development User', 'admin', 
     '{"theme": "dark", "language": "en", "notifications": true}', 
     '{"auto_sync": true, "batch_size": 10}', 500.00),
    ('22222222-2222-2222-2222-222222222222', 'test@brain.ai', 'Test User', 'user',
     '{"theme": "light", "language": "en", "notifications": false}',
     '{"auto_sync": false, "batch_size": 5}', 100.00),
    ('33333333-3333-3333-3333-333333333333', 'qa@brain.ai', 'QA User', 'user',
     '{"theme": "auto", "language": "en", "notifications": true}',
     '{"auto_sync": true, "batch_size": 15}', 250.00)
ON CONFLICT (email) DO UPDATE SET
    display_name = EXCLUDED.display_name,
    preferences = EXCLUDED.preferences,
    settings = EXCLUDED.settings,
    monthly_budget_limit = EXCLUDED.monthly_budget_limit,
    updated_at = CURRENT_TIMESTAMP;

-- ========================================
-- SAMPLE FOLDERS
-- ========================================

INSERT INTO folders (id, user_id, google_folder_id, folder_name, folder_path, auto_sync_enabled, sync_frequency_minutes, file_type_filters, total_files, processed_files) VALUES
    ('aaaa1111-bbbb-2222-cccc-333333333333', '11111111-1111-1111-1111-111111111111', 'dev_folder_1', 'Development Documents', '/dev/docs', true, 30, ARRAY['pdf', 'docx', 'md'], 25, 20),
    ('aaaa2222-bbbb-3333-cccc-444444444444', '11111111-1111-1111-1111-111111111111', 'dev_folder_2', 'Technical Specs', '/dev/specs', true, 60, ARRAY['pdf', 'md', 'txt'], 15, 12),
    ('aaaa3333-bbbb-4444-cccc-555555555555', '22222222-2222-2222-2222-222222222222', 'test_folder_1', 'Test Documents', '/test/docs', false, 120, ARRAY['pdf', 'docx'], 8, 5),
    ('aaaa4444-bbbb-5555-cccc-666666666666', '33333333-3333-3333-3333-333333333333', 'qa_folder_1', 'QA Test Cases', '/qa/tests', true, 45, ARRAY['md', 'txt', 'json'], 30, 28)
ON CONFLICT (user_id, google_folder_id) DO UPDATE SET
    folder_name = EXCLUDED.folder_name,
    folder_path = EXCLUDED.folder_path,
    auto_sync_enabled = EXCLUDED.auto_sync_enabled,
    sync_frequency_minutes = EXCLUDED.sync_frequency_minutes,
    updated_at = CURRENT_TIMESTAMP;

-- ========================================
-- SAMPLE DOCUMENTS
-- ========================================

-- Note: In a real system, embeddings would be generated by AI models
-- For development, we'll use placeholder vectors or NULL
INSERT INTO documents (
    id, folder_id, user_id, google_file_id, file_name, file_path, mime_type, file_size_bytes,
    document_type, content_hash, language_code, raw_text, processed_text, text_length,
    extraction_quality, processing_cost, token_count, processing_status, 
    metadata, tags
) VALUES
    ('dddd1111-eeee-2222-ffff-333333333333', 'aaaa1111-bbbb-2222-cccc-333333333333', '11111111-1111-1111-1111-111111111111', 
     'google_file_1', 'API_Documentation.pdf', '/dev/docs/API_Documentation.pdf', 'application/pdf', 1024000,
     'pdf', 'sha256_hash_1', 'en', 'This is the raw text from API documentation...', 'This is the processed API documentation text...', 2500,
     0.95, 0.0025, 1250, 'completed',
     '{"author": "Dev Team", "version": "1.0", "pages": 15}', ARRAY['api', 'documentation', 'development']),
    
    ('dddd2222-eeee-3333-ffff-444444444444', 'aaaa1111-bbbb-2222-cccc-333333333333', '11111111-1111-1111-1111-111111111111',
     'google_file_2', 'Database_Schema.md', '/dev/docs/Database_Schema.md', 'text/markdown', 45000,
     'md', 'sha256_hash_2', 'en', 'Database schema documentation...', 'Processed database schema information...', 3200,
     0.88, 0.0032, 1600, 'completed',
     '{"author": "Architect", "last_updated": "2025-09-11"}', ARRAY['database', 'schema', 'documentation']),
     
    ('dddd3333-eeee-4444-ffff-555555555555', 'aaaa2222-bbbb-3333-cccc-444444444444', '11111111-1111-1111-1111-111111111111',
     'google_file_3', 'Technical_Requirements.docx', '/dev/specs/Technical_Requirements.docx', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 890000,
     'docx', 'sha256_hash_3', 'en', 'Technical requirements document text...', 'Processed technical requirements...', 5800,
     0.92, 0.0058, 2900, 'completed',
     '{"author": "Product Manager", "status": "approved", "version": "2.1"}', ARRAY['requirements', 'technical', 'specifications']),
     
    ('dddd4444-eeee-5555-ffff-666666666666', 'aaaa3333-bbbb-4444-cccc-555555555555', '22222222-2222-2222-2222-222222222222',
     'google_file_4', 'Test_Plan.pdf', '/test/docs/Test_Plan.pdf', 'application/pdf', 720000,
     'pdf', 'sha256_hash_4', 'en', 'Test plan document content...', 'Processed test plan content...', 4100,
     0.85, 0.0041, 2050, 'completed',
     '{"test_type": "integration", "coverage": "85%"}', ARRAY['testing', 'plan', 'integration']),
     
    ('dddd5555-eeee-6666-ffff-777777777777', 'aaaa4444-bbbb-5555-cccc-666666666666', '33333333-3333-3333-3333-333333333333',
     'google_file_5', 'QA_Checklist.md', '/qa/tests/QA_Checklist.md', 'text/markdown', 25000,
     'md', 'sha256_hash_5', 'en', 'QA checklist markdown content...', 'Processed QA checklist...', 1800,
     0.90, 0.0018, 900, 'completed',
     '{"checklist_version": "3.0", "last_review": "2025-09-10"}', ARRAY['qa', 'checklist', 'quality']),
     
    -- Some documents in processing
    ('dddd6666-eeee-7777-ffff-888888888888', 'aaaa1111-bbbb-2222-cccc-333333333333', '11111111-1111-1111-1111-111111111111',
     'google_file_6', 'Large_Document.pdf', '/dev/docs/Large_Document.pdf', 'application/pdf', 5000000,
     'pdf', 'sha256_hash_6', 'en', NULL, NULL, NULL,
     NULL, NULL, NULL, 'processing',
     '{"estimated_pages": 200}', ARRAY['large', 'processing']),
     
    ('dddd7777-eeee-8888-ffff-999999999999', 'aaaa2222-bbbb-3333-cccc-444444444444', '11111111-1111-1111-1111-111111111111',
     'google_file_7', 'Failed_Document.docx', '/dev/specs/Failed_Document.docx', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 1200000,
     'docx', 'sha256_hash_7', 'en', NULL, NULL, NULL,
     NULL, NULL, NULL, 'failed',
     '{"error_reason": "corrupted_file"}', ARRAY['failed', 'corrupted'])
ON CONFLICT (google_file_id) DO UPDATE SET
    file_name = EXCLUDED.file_name,
    extraction_quality = EXCLUDED.extraction_quality,
    processing_cost = EXCLUDED.processing_cost,
    updated_at = CURRENT_TIMESTAMP;

-- ========================================
-- SAMPLE KNOWLEDGE NODES
-- ========================================

INSERT INTO knowledge_nodes (
    id, user_id, node_type, node_value, normalized_value, source_document_id,
    confidence_score, context, metadata, mention_count, document_count
) VALUES
    ('kkkk1111-nnnn-2222-oooo-333333333333', '11111111-1111-1111-1111-111111111111', 'concept', 'REST API', 'rest api', 'dddd1111-eeee-2222-ffff-333333333333',
     0.95, 'The REST API provides endpoints for...', '{"category": "technical", "importance": "high"}', 8, 2),
     
    ('kkkk2222-nnnn-3333-oooo-444444444444', '11111111-1111-1111-1111-111111111111', 'entity', 'PostgreSQL', 'postgresql', 'dddd2222-eeee-3333-ffff-444444444444',
     0.92, 'PostgreSQL database with pgvector extension...', '{"type": "database", "version": "15"}', 12, 3),
     
    ('kkkk3333-nnnn-4444-oooo-555555555555', '11111111-1111-1111-1111-111111111111', 'concept', 'Vector Embeddings', 'vector embeddings', 'dddd1111-eeee-2222-ffff-333333333333',
     0.88, 'Vector embeddings for semantic search...', '{"dimensions": 1536, "model": "text-embedding-3-small"}', 5, 2),
     
    ('kkkk4444-nnnn-5555-oooo-666666666666', '22222222-2222-2222-2222-222222222222', 'concept', 'Integration Testing', 'integration testing', 'dddd4444-eeee-5555-ffff-666666666666',
     0.90, 'Integration testing approach for...', '{"test_type": "automated", "coverage": "85%"}', 6, 1),
     
    ('kkkk5555-nnnn-6666-oooo-777777777777', '33333333-3333-3333-3333-333333333333', 'concept', 'Quality Assurance', 'quality assurance', 'dddd5555-eeee-6666-ffff-777777777777',
     0.93, 'Quality assurance processes and procedures...', '{"methodology": "agile", "tools": ["pytest", "selenium"]}', 4, 1)
ON CONFLICT (user_id, node_type, normalized_value) DO UPDATE SET
    mention_count = knowledge_nodes.mention_count + EXCLUDED.mention_count,
    updated_at = CURRENT_TIMESTAMP;

-- ========================================
-- SAMPLE KNOWLEDGE EDGES
-- ========================================

INSERT INTO knowledge_edges (
    id, user_id, source_node_id, target_node_id, edge_type, weight, confidence_score,
    source_document_id, evidence_text, context
) VALUES
    ('eeee1111-dddd-2222-gggg-333333333333', '11111111-1111-1111-1111-111111111111', 
     'kkkk1111-nnnn-2222-oooo-333333333333', 'kkkk3333-nnnn-4444-oooo-555555555555', 'uses', 0.85, 0.90,
     'dddd1111-eeee-2222-ffff-333333333333', 'The REST API uses vector embeddings for semantic search',
     '{"relationship_strength": "strong", "context": "technical_implementation"}'),
     
    ('eeee2222-dddd-3333-gggg-444444444444', '11111111-1111-1111-1111-111111111111',
     'kkkk2222-nnnn-3333-oooo-444444444444', 'kkkk3333-nnnn-4444-oooo-555555555555', 'stores', 0.90, 0.88,
     'dddd2222-eeee-3333-ffff-444444444444', 'PostgreSQL stores vector embeddings using pgvector',
     '{"storage_method": "pgvector", "index_type": "hnsw"}'),
     
    ('eeee3333-dddd-4444-gggg-555555555555', '22222222-2222-2222-2222-222222222222',
     'kkkk4444-nnnn-5555-oooo-666666666666', 'kkkk5555-nnnn-6666-oooo-777777777777', 'part_of', 0.75, 0.85,
     'dddd4444-eeee-5555-ffff-666666666666', 'Integration testing is part of quality assurance',
     '{"qa_phase": "testing", "automation_level": "high"}')
ON CONFLICT (user_id, source_node_id, target_node_id, edge_type) DO UPDATE SET
    weight = EXCLUDED.weight,
    confidence_score = EXCLUDED.confidence_score,
    updated_at = CURRENT_TIMESTAMP;

-- ========================================
-- SAMPLE LLM USAGE DATA
-- ========================================

-- Generate sample LLM usage data for the past 7 days
INSERT INTO llm_usage (
    user_id, operation_type, model_name, input_tokens, output_tokens, 
    input_cost_per_token, output_cost_per_token, latency_ms, document_id,
    created_at, completed_at
) VALUES
    -- Recent embeddings
    ('11111111-1111-1111-1111-111111111111', 'embedding', 'text-embedding-3-small', 1250, 0, 0.00000002, 0.0, 150, 'dddd1111-eeee-2222-ffff-333333333333', CURRENT_TIMESTAMP - INTERVAL '1 hour', CURRENT_TIMESTAMP - INTERVAL '1 hour' + INTERVAL '150 milliseconds'),
    ('11111111-1111-1111-1111-111111111111', 'embedding', 'text-embedding-3-small', 1600, 0, 0.00000002, 0.0, 200, 'dddd2222-eeee-3333-ffff-444444444444', CURRENT_TIMESTAMP - INTERVAL '2 hours', CURRENT_TIMESTAMP - INTERVAL '2 hours' + INTERVAL '200 milliseconds'),
    ('11111111-1111-1111-1111-111111111111', 'embedding', 'text-embedding-3-small', 2900, 0, 0.00000002, 0.0, 350, 'dddd3333-eeee-4444-ffff-555555555555', CURRENT_TIMESTAMP - INTERVAL '3 hours', CURRENT_TIMESTAMP - INTERVAL '3 hours' + INTERVAL '350 milliseconds'),
    
    -- Some completions for text processing
    ('11111111-1111-1111-1111-111111111111', 'completion', 'gpt-4-turbo-preview', 500, 200, 0.00001, 0.00003, 2500, 'dddd1111-eeee-2222-ffff-333333333333', CURRENT_TIMESTAMP - INTERVAL '1 day', CURRENT_TIMESTAMP - INTERVAL '1 day' + INTERVAL '2.5 seconds'),
    ('22222222-2222-2222-2222-222222222222', 'embedding', 'text-embedding-3-small', 2050, 0, 0.00000002, 0.0, 250, 'dddd4444-eeee-5555-ffff-666666666666', CURRENT_TIMESTAMP - INTERVAL '6 hours', CURRENT_TIMESTAMP - INTERVAL '6 hours' + INTERVAL '250 milliseconds'),
    ('33333333-3333-3333-3333-333333333333', 'embedding', 'text-embedding-3-small', 900, 0, 0.00000002, 0.0, 120, 'dddd5555-eeee-6666-ffff-777777777777', CURRENT_TIMESTAMP - INTERVAL '4 hours', CURRENT_TIMESTAMP - INTERVAL '4 hours' + INTERVAL '120 milliseconds'),
    
    -- Historical data for trends (past week)
    ('11111111-1111-1111-1111-111111111111', 'embedding', 'text-embedding-3-small', 1800, 0, 0.00000002, 0.0, 180, NULL, CURRENT_TIMESTAMP - INTERVAL '2 days', CURRENT_TIMESTAMP - INTERVAL '2 days' + INTERVAL '180 milliseconds'),
    ('11111111-1111-1111-1111-111111111111', 'embedding', 'text-embedding-3-small', 2200, 0, 0.00000002, 0.0, 220, NULL, CURRENT_TIMESTAMP - INTERVAL '3 days', CURRENT_TIMESTAMP - INTERVAL '3 days' + INTERVAL '220 milliseconds'),
    ('11111111-1111-1111-1111-111111111111', 'completion', 'gpt-4-turbo-preview', 800, 300, 0.00001, 0.00003, 3200, NULL, CURRENT_TIMESTAMP - INTERVAL '4 days', CURRENT_TIMESTAMP - INTERVAL '4 days' + INTERVAL '3.2 seconds'),
    ('22222222-2222-2222-2222-222222222222', 'embedding', 'text-embedding-3-small', 1200, 0, 0.00000002, 0.0, 140, NULL, CURRENT_TIMESTAMP - INTERVAL '5 days', CURRENT_TIMESTAMP - INTERVAL '5 days' + INTERVAL '140 milliseconds');

-- ========================================
-- SAMPLE SYSTEM HEALTH DATA
-- ========================================

-- Insert recent system health data
INSERT INTO system_health (
    service_name, status, response_time_ms, cpu_percent, memory_mb, 
    active_connections, requests_per_minute, error_rate_percent,
    measured_at
) VALUES
    ('backend', 'healthy', 45, 15.5, 512, 8, 120, 0.2, CURRENT_TIMESTAMP - INTERVAL '5 minutes'),
    ('postgres', 'healthy', 8, 25.3, 1024, 12, 0, 0.0, CURRENT_TIMESTAMP - INTERVAL '5 minutes'),
    ('redis', 'healthy', 2, 8.7, 128, 3, 0, 0.0, CURRENT_TIMESTAMP - INTERVAL '5 minutes'),
    ('websocket', 'healthy', 12, 5.2, 256, 4, 45, 0.1, CURRENT_TIMESTAMP - INTERVAL '5 minutes'),
    
    -- Historical data points for trending
    ('backend', 'healthy', 50, 18.2, 520, 10, 130, 0.3, CURRENT_TIMESTAMP - INTERVAL '1 hour'),
    ('postgres', 'healthy', 10, 22.1, 1020, 11, 0, 0.0, CURRENT_TIMESTAMP - INTERVAL '1 hour'),
    ('redis', 'healthy', 3, 9.1, 130, 3, 0, 0.0, CURRENT_TIMESTAMP - INTERVAL '1 hour'),
    ('websocket', 'warning', 25, 12.5, 280, 6, 60, 1.2, CURRENT_TIMESTAMP - INTERVAL '1 hour');

-- ========================================
-- SAMPLE ALERT RULES
-- ========================================

INSERT INTO alert_rules (
    user_id, rule_name, rule_type, description, metric_name, operator, threshold_value,
    evaluation_window_minutes, enabled, severity, notification_channels
) VALUES
    ('11111111-1111-1111-1111-111111111111', 'Daily Cost Limit', 'cost_threshold', 'Alert when daily cost exceeds $10', 'daily_cost', 'greater_than', 10.0, 1440, true, 'warning', ARRAY['email']),
    ('11111111-1111-1111-1111-111111111111', 'High Error Rate', 'error_rate', 'Alert when error rate exceeds 5%', 'error_rate', 'greater_than', 5.0, 60, true, 'critical', ARRAY['email', 'slack']),
    ('22222222-2222-2222-2222-222222222222', 'Budget Warning', 'cost_threshold', 'Alert at 80% of monthly budget', 'monthly_cost', 'greater_than', 80.0, 1440, true, 'warning', ARRAY['email']),
    ('33333333-3333-3333-3333-333333333333', 'Processing Delays', 'performance', 'Alert when average processing time > 5 seconds', 'avg_processing_time', 'greater_than', 5000.0, 120, true, 'warning', ARRAY['email'])
ON CONFLICT (user_id, rule_name) DO NOTHING;

-- ========================================
-- SAMPLE PROCESSING QUEUE ITEMS
-- ========================================

INSERT INTO processing_queue (
    user_id, document_id, folder_id, task_type, task_data, priority, status, scheduled_for
) VALUES
    ('11111111-1111-1111-1111-111111111111', 'dddd6666-eeee-7777-ffff-888888888888', 'aaaa1111-bbbb-2222-cccc-333333333333', 'extract', '{"format": "pdf", "options": {"ocr": true}}', 8, 'pending', CURRENT_TIMESTAMP + INTERVAL '5 minutes'),
    ('11111111-1111-1111-1111-111111111111', NULL, 'aaaa1111-bbbb-2222-cccc-333333333333', 'sync', '{"full_sync": false, "incremental": true}', 5, 'pending', CURRENT_TIMESTAMP + INTERVAL '15 minutes'),
    ('22222222-2222-2222-2222-222222222222', NULL, 'aaaa3333-bbbb-4444-cccc-555555555555', 'analyze', '{"analysis_type": "summary"}', 3, 'pending', CURRENT_TIMESTAMP + INTERVAL '30 minutes');

-- ========================================
-- TRIGGER MATERIALIZED VIEW REFRESH
-- ========================================

-- Refresh materialized views with the new data
-- Note: In production, this would be handled by the refresh_all_materialized_views() function
REFRESH MATERIALIZED VIEW document_search_view;
REFRESH MATERIALIZED VIEW knowledge_graph_analytics_view;
REFRESH MATERIALIZED VIEW cost_analytics_view;

-- ========================================
-- SUMMARY STATISTICS
-- ========================================

-- This provides a quick overview of the seeded data
DO $$
DECLARE
    user_count INTEGER;
    folder_count INTEGER;
    document_count INTEGER;
    node_count INTEGER;
    edge_count INTEGER;
    usage_count INTEGER;
BEGIN
    SELECT COUNT(*) INTO user_count FROM users WHERE id NOT LIKE '00000000-%';
    SELECT COUNT(*) INTO folder_count FROM folders;
    SELECT COUNT(*) INTO document_count FROM documents;
    SELECT COUNT(*) INTO node_count FROM knowledge_nodes;
    SELECT COUNT(*) INTO edge_count FROM knowledge_edges;
    SELECT COUNT(*) INTO usage_count FROM llm_usage;
    
    RAISE NOTICE 'Development seed data loaded successfully:';
    RAISE NOTICE '  - Users: %', user_count;
    RAISE NOTICE '  - Folders: %', folder_count;
    RAISE NOTICE '  - Documents: %', document_count;
    RAISE NOTICE '  - Knowledge Nodes: %', node_count;
    RAISE NOTICE '  - Knowledge Edges: %', edge_count;
    RAISE NOTICE '  - LLM Usage Records: %', usage_count;
    RAISE NOTICE 'Ready for development and testing!';
END $$;